{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this model, we will train the data using the mel-spectrogram figures. For this, we will first store them as images and then using them, train a 2D CNN which will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-f2c247e902ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for label in labels : \n",
    "    label_data = np.load(label + \".npy\")\n",
    "    for arr in label_data:\n",
    "        D = np.abs(librosa.stft(arr))**2\n",
    "        S = librosa.feature.melspectrogram(S=D, sr=16000, n_mels=128, fmax=8000)\n",
    "        K = librosa.power_to_db(S,ref=np.max)\n",
    "        temp = [[label, K]]\n",
    "        data += temp\n",
    "data = pd.DataFrame(data, columns=[\"Label\", \"Spectrogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'another_model.ipynb', 'checkpoints', 'down.npy', 'filenameset.npy', 'go.npy', 'left.npy', 'link_to_gcp_credits_form.txt', 'model3.ipynb', 'New folder', 'no.npy', 'off.npy', 'on.npy', 'resimages.npy', 'reslabels.npy', 'right.npy', 'sample_submission', 'sample_submission.7z', 'Second.ipynb', 'silence.npy', 'spectrogram_training_set.ipynb', 'stop.npy', 'Tensor Flow Challenge.ipynb', 'test', 'test.7z', 'testingset.npy', 'test_images', 'train', 'train.7z', 'training_again-Copy1.ipynb', 'training_again.ipynb', 'training_data.ipynb', 'training_set', 'unknown', 'unknown.npy', 'Untitled.ipynb', 'up.npy', 'x_train.npy', 'yes.npy', 'y_res.npy', 'y_train.npy', '_init_.ipynb']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9a683864a84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpectrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "dir_path = \"training_set\"\n",
    "print(os.listdir())\n",
    "if(dir_path not in os.listdir()):\n",
    "    os.mkdir(dir_path)\n",
    "    for i in labels:\n",
    "        os.mkdir(os.path.join(dir_path, i))\n",
    "\n",
    "prev = np.zeros((128,32))\n",
    "for i in range(data.shape[0]):\n",
    "    label = data.iloc[i].Label\n",
    "    spectrogram = data.iloc[i].Spectrogram\n",
    "    print(prev == spectrogram) \n",
    "    prev = spectrogram\n",
    "    plt.imsave(os.path.join(dir_path, label, str(i) + \".png\"), spectrogram)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resimages = [] \n",
    "reslabels = []\n",
    "dir_path = \"training_set\"\n",
    "k=0\n",
    "prev = np.zeros((128,32))\n",
    "for label in os.listdir(dir_path):\n",
    "    for file in os.listdir(os.path.join(dir_path, label)):\n",
    "        img = cv2.imread(os.path.join(dir_path, label, file))\n",
    "#         print(img.shape)\n",
    "#         print(np.array_equal(prev, img))\n",
    "        prev = img\n",
    "        resimages.append(img)\n",
    "        reslabels.append(label)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resimages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-268f0b50c39e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreslabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreslabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreslabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"resimages\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resimages' is not defined"
     ]
    }
   ],
   "source": [
    "resimages = np.array(resimages)\n",
    "reslabels = np.array(reslabels)\n",
    "print(resimages.shape)\n",
    "print(reslabels.shape)\n",
    "np.save(\"resimages\", resimages)\n",
    "np.save(\"reslabels\", reslabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(\"resimages.npy\")\n",
    "reslabels = np.load(\"reslabels.npy\")\n",
    "# print(reslabels)\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(reslabels)\n",
    "# print(train_labels)\n",
    "# print(le.inverse_transform(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = model_selection.train_test_split(train_images, reslabels, test_size=0.2)\n",
    "def create_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(128 , (3,3), activation='softmax', input_shape=(128, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128 , (3,3), activation='softmax', input_shape=(128, 32, 3)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(12))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reslabels.shape)\n",
    "print(train_images.shape)\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10,  batch_size=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(xtr, ytr, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(xte, yte, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum accuracy achieved by this model was 85% on the training set. Hence we will use this model on our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1d5abfcdca0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = create_model()\n",
    "model_new.load_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538\n"
     ]
    }
   ],
   "source": [
    "testing_folder = os.path.join(\"test\", \"audio\")\n",
    "print(len(os.listdir(testing_folder)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = os.path.join(\"test_images\")\n",
    "if(destination_folder not in os.listdir()):\n",
    "    os.mkdir(destination_folder)\n",
    "testingset = []\n",
    "filenameset = []\n",
    "prev = np.zeros((128,32, 3))\n",
    "prev_file = \"\"\n",
    "for audio_file in os.listdir(testing_folder):\n",
    "    file_name = audio_file[0:-4]\n",
    "    audio_file_path = os.path.join(testing_folder, audio_file)\n",
    "    audio_file_arr, sr = librosa.load(audio_file_path, sr=16000)\n",
    "    conv_numpy = librosa.util.fix_length(audio_file_arr, 16000)\n",
    "    D = np.abs(librosa.stft(audio_file_arr))**2\n",
    "    S = librosa.feature.melspectrogram(S=D, sr=16000, n_mels=128, fmax=8000)\n",
    "    K = librosa.power_to_db(S,ref=np.max)\n",
    "    plt.imsave(os.path.join(destination_folder, file_name+\".png\"), K)\n",
    "    img = cv2.imread(os.path.join(destination_folder, file_name + \".png\"))\n",
    "    prev = img\n",
    "    prev_file = file_name\n",
    "    testingset.append(img)\n",
    "    filenameset.append(audio_file + \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538\n",
      "(158538, 128, 32, 3)\n",
      "(158538,)\n"
     ]
    }
   ],
   "source": [
    "print(len(testingset))\n",
    "testing_set = np.array(testingset)\n",
    "filename_set  = np.array(filenameset)\n",
    "print(testing_set.shape)\n",
    "print(filename_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"testing_set\", testing_set)\n",
    "np.save(\"filename_set\", filename_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_set = np.load(\"testing_set.npy\")\n",
    "filename_set = np.load(\"filename_set.npy\")\n",
    "filename = \"submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = model_new.predict_classes(testingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res_2 = np.argmax(model_new.predict(testing_set), axis=-1)\n",
    "# print(le.inverse_transform(y_res))\n",
    "# print(le.inverse_transform(y_res_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 5 ... 5 7 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(y_res_2)\n",
    "\n",
    "np.save(\"result\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(\"result.npy\")\n",
    "res_label = le.inverse_transform(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = []\n",
    "\n",
    "for i in range(len(res)):\n",
    "    file_data.append([filename_set[i][0:-4], res_label[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clip_000044442.wav', 'no']\n",
      "['clip_0000adecb.wav', 'unknown']\n",
      "['clip_0000d4322.wav', 'on']\n",
      "['clip_0000fb6fe.wav', 'unknown']\n",
      "['clip_0001d1559.wav', 'unknown']\n",
      "['clip_0002256ed.wav', 'unknown']\n",
      "['clip_0002a4a1f.wav', 'on']\n",
      "['clip_0002d9b83.wav', 'unknown']\n",
      "['clip_000373a5b.wav', 'go']\n",
      "['clip_0003c7122.wav', 'right']\n",
      "['clip_0003e6aee.wav', 'off']\n",
      "['clip_00049951d.wav', 'unknown']\n",
      "['clip_0004c6707.wav', 'off']\n",
      "['clip_0004f8b63.wav', 'left']\n",
      "['clip_00068e281.wav', 'no']\n",
      "['clip_00069e9cb.wav', 'stop']\n",
      "['clip_0006f7b8b.wav', 'left']\n",
      "['clip_0007ec7e6.wav', 'down']\n",
      "['clip_00082a7d6.wav', 'unknown']\n",
      "['clip_00094eb22.wav', 'on']\n",
      "['clip_000962cbb.wav', 'unknown']\n",
      "['clip_000a96d0a.wav', 'unknown']\n",
      "['clip_000b01093.wav', 'unknown']\n",
      "['clip_000b378f1.wav', 'unknown']\n",
      "['clip_000b9514b.wav', 'unknown']\n",
      "['clip_000c07b07.wav', 'unknown']\n",
      "['clip_000c2c07b.wav', 'unknown']\n",
      "['clip_000c41da7.wav', 'on']\n",
      "['clip_000dcdd2c.wav', 'silence']\n",
      "['clip_000ed5715.wav', 'down']\n",
      "['clip_000f49605.wav', 'unknown']\n",
      "['clip_000f913a0.wav', 'unknown']\n",
      "['clip_000fb64da.wav', 'no']\n",
      "['clip_00101f620.wav', 'stop']\n",
      "['clip_0010605bd.wav', 'down']\n",
      "['clip_00111068b.wav', 'unknown']\n",
      "['clip_0011dcf3c.wav', 'no']\n",
      "['clip_001204892.wav', 'up']\n",
      "['clip_00123c913.wav', 'silence']\n",
      "['clip_00127975d.wav', 'unknown']\n",
      "['clip_001280676.wav', 'on']\n",
      "['clip_00134bbac.wav', 'unknown']\n",
      "['clip_00136750b.wav', 'unknown']\n",
      "['clip_00139d600.wav', 'off']\n",
      "['clip_0013a6ef3.wav', 'left']\n",
      "['clip_00147bbb6.wav', 'unknown']\n",
      "['clip_0014ea384.wav', 'yes']\n",
      "['clip_0014ed3d5.wav', 'no']\n",
      "['clip_0014f2f18.wav', 'no']\n",
      "['clip_00150496f.wav', 'unknown']\n",
      "['clip_0015cb701.wav', 'unknown']\n",
      "['clip_0015fa156.wav', 'on']\n",
      "['clip_00169a7f7.wav', 'unknown']\n",
      "['clip_0017365f5.wav', 'go']\n",
      "['clip_0017714af.wav', 'unknown']\n",
      "['clip_00178d644.wav', 'no']\n",
      "['clip_0017bb9a0.wav', 'unknown']\n",
      "['clip_0018489ca.wav', 'silence']\n",
      "['clip_001849d72.wav', 'unknown']\n",
      "['clip_0018a2032.wav', 'silence']\n",
      "['clip_0018ff8e9.wav', 'no']\n",
      "['clip_001a5ce9c.wav', 'stop']\n",
      "['clip_001a97e40.wav', 'down']\n",
      "['clip_001aa40fc.wav', 'up']\n",
      "['clip_001aeb352.wav', 'up']\n",
      "['clip_001ba5f87.wav', 'off']\n",
      "['clip_001bd519d.wav', 'down']\n",
      "['clip_001c3e626.wav', 'left']\n",
      "['clip_001c90db9.wav', 'no']\n",
      "['clip_001ce7baf.wav', 'unknown']\n",
      "['clip_001d11778.wav', 'left']\n",
      "['clip_001eadba5.wav', 'unknown']\n",
      "['clip_001f1506f.wav', 'go']\n",
      "['clip_001f39338.wav', 'unknown']\n",
      "['clip_001fd434c.wav', 'unknown']\n",
      "['clip_001fdd23a.wav', 'unknown']\n",
      "['clip_002011429.wav', 'no']\n",
      "['clip_00209953c.wav', 'unknown']\n",
      "['clip_0020a49ad.wav', 'unknown']\n",
      "['clip_002130efd.wav', 'unknown']\n",
      "['clip_0021662c3.wav', 'unknown']\n",
      "['clip_00219963b.wav', 'unknown']\n",
      "['clip_0022ed555.wav', 'right']\n",
      "['clip_002348727.wav', 'unknown']\n",
      "['clip_0023980f9.wav', 'down']\n",
      "['clip_0023bf6a0.wav', 'unknown']\n",
      "['clip_0023ed3f3.wav', 'down']\n",
      "['clip_0023f6e02.wav', 'stop']\n",
      "['clip_0024320a1.wav', 'off']\n",
      "['clip_00246e676.wav', 'silence']\n",
      "['clip_0024bfdde.wav', 'on']\n",
      "['clip_002549abb.wav', 'left']\n",
      "['clip_0025e94de.wav', 'right']\n",
      "['clip_002623fd6.wav', 'unknown']\n",
      "['clip_00262610a.wav', 'go']\n",
      "['clip_002649edd.wav', 'unknown']\n",
      "['clip_0026d5853.wav', 'go']\n",
      "['clip_0026f08f3.wav', 'unknown']\n",
      "['clip_002716f99.wav', 'unknown']\n",
      "['clip_00275568b.wav', 'on']\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(file_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538\n"
     ]
    }
   ],
   "source": [
    "print(len(file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(file_data, columns = [\"Fname\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Submission_2.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
