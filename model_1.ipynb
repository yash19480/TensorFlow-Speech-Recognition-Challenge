{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as spy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"yes.npy\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will load the training data into label.npy arrays and then use them. For this model we are using the mfcc array for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2377, 16000)\n",
      "(2375, 16000)\n",
      "(2375, 16000)\n",
      "(2359, 16000)\n",
      "(2353, 16000)\n",
      "(2367, 16000)\n",
      "(2367, 16000)\n",
      "(2357, 16000)\n",
      "(2380, 16000)\n",
      "(2372, 16000)\n",
      "(398, 16000)\n",
      "(4096, 16000)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "#we will consider the mfcc foor x_train\n",
    "k = []\n",
    "for label in labels :\n",
    "    data_label = np.load(label +\".npy\")\n",
    "    print(data_label.shape)\n",
    "    for arr in data_label :\n",
    "#         print(arr.shape)\n",
    "        mfcc_arr = librosa.feature.mfcc(arr)\n",
    "        mfcc_arr = np.mean(mfcc_arr, axis=0)\n",
    "#         print(mfcc_arr.shape)\n",
    "        x_train.append(mfcc_arr)\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28176, 32)\n",
      "(28176,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "np.save(\"x_train.npy\", x_train)\n",
    "np.save(\"y_train.npy\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will try to apply PCA to extract the main features from our training data and then use them for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components = 12) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28176, 12)\n"
     ]
    }
   ],
   "source": [
    "x_train = pca.fit_transform(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will perform label encoding on our given labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28176,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a very simple neural network for our data consisting of 4 layers and train our model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22540, 12)\n",
      "(22540,)\n",
      "(5636, 12)\n",
      "(5636,)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from sklearn import model_selection\n",
    "from datetime import datetime \n",
    "\n",
    "xtr, xte, ytr, yte = model_selection.train_test_split(x_train, y_train, test_size=0.2)\n",
    "print(xtr.shape)\n",
    "print(ytr.shape)\n",
    "print(xte.shape)\n",
    "print(yte.shape)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation='softmax', input_shape=(xtr.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22540, 12)\n",
      "Epoch 1/100\n",
      "564/564 [==============================] - 1s 777us/step - loss: 2.4236 - accuracy: 0.1490\n",
      "Epoch 2/100\n",
      "564/564 [==============================] - 0s 760us/step - loss: 2.3149 - accuracy: 0.1755\n",
      "Epoch 3/100\n",
      "564/564 [==============================] - 0s 766us/step - loss: 2.2700 - accuracy: 0.1910\n",
      "Epoch 4/100\n",
      "564/564 [==============================] - 0s 744us/step - loss: 2.2413 - accuracy: 0.1979\n",
      "Epoch 5/100\n",
      "564/564 [==============================] - 0s 765us/step - loss: 2.2075 - accuracy: 0.2092\n",
      "Epoch 6/100\n",
      "564/564 [==============================] - 0s 795us/step - loss: 2.1916 - accuracy: 0.2175\n",
      "Epoch 7/100\n",
      "564/564 [==============================] - 0s 733us/step - loss: 2.1688 - accuracy: 0.2241\n",
      "Epoch 8/100\n",
      "564/564 [==============================] - 0s 779us/step - loss: 2.1535 - accuracy: 0.2353\n",
      "Epoch 9/100\n",
      "564/564 [==============================] - 0s 756us/step - loss: 2.1494 - accuracy: 0.2308\n",
      "Epoch 10/100\n",
      "564/564 [==============================] - 0s 752us/step - loss: 2.1215 - accuracy: 0.2432\n",
      "Epoch 11/100\n",
      "564/564 [==============================] - 0s 754us/step - loss: 2.1129 - accuracy: 0.2484\n",
      "Epoch 12/100\n",
      "564/564 [==============================] - 0s 732us/step - loss: 2.0965 - accuracy: 0.2531\n",
      "Epoch 13/100\n",
      "564/564 [==============================] - 0s 788us/step - loss: 2.0982 - accuracy: 0.2497\n",
      "Epoch 14/100\n",
      "564/564 [==============================] - 0s 722us/step - loss: 2.0827 - accuracy: 0.2600\n",
      "Epoch 15/100\n",
      "564/564 [==============================] - 0s 777us/step - loss: 2.0746 - accuracy: 0.2634\n",
      "Epoch 16/100\n",
      "564/564 [==============================] - 0s 752us/step - loss: 2.0575 - accuracy: 0.2663\n",
      "Epoch 17/100\n",
      "564/564 [==============================] - 0s 736us/step - loss: 2.0453 - accuracy: 0.2726\n",
      "Epoch 18/100\n",
      "564/564 [==============================] - 0s 758us/step - loss: 2.0452 - accuracy: 0.2785\n",
      "Epoch 19/100\n",
      "564/564 [==============================] - 0s 719us/step - loss: 2.0305 - accuracy: 0.2752\n",
      "Epoch 20/100\n",
      "564/564 [==============================] - 0s 759us/step - loss: 2.0166 - accuracy: 0.2878\n",
      "Epoch 21/100\n",
      "564/564 [==============================] - 0s 752us/step - loss: 2.0023 - accuracy: 0.2864\n",
      "Epoch 22/100\n",
      "564/564 [==============================] - 0s 761us/step - loss: 1.9947 - accuracy: 0.2908\n",
      "Epoch 23/100\n",
      "564/564 [==============================] - 0s 829us/step - loss: 1.9795 - accuracy: 0.2970\n",
      "Epoch 24/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.9701 - accuracy: 0.3038\n",
      "Epoch 25/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.9573 - accuracy: 0.3118\n",
      "Epoch 26/100\n",
      "564/564 [==============================] - 0s 738us/step - loss: 1.9437 - accuracy: 0.3107\n",
      "Epoch 27/100\n",
      "564/564 [==============================] - 0s 713us/step - loss: 1.9277 - accuracy: 0.3163\n",
      "Epoch 28/100\n",
      "564/564 [==============================] - 0s 731us/step - loss: 1.9399 - accuracy: 0.3170\n",
      "Epoch 29/100\n",
      "564/564 [==============================] - 0s 739us/step - loss: 1.9272 - accuracy: 0.3158\n",
      "Epoch 30/100\n",
      "564/564 [==============================] - 0s 783us/step - loss: 1.9176 - accuracy: 0.3188\n",
      "Epoch 31/100\n",
      "564/564 [==============================] - 1s 915us/step - loss: 1.9068 - accuracy: 0.3277\n",
      "Epoch 32/100\n",
      "564/564 [==============================] - 0s 722us/step - loss: 1.8982 - accuracy: 0.3270\n",
      "Epoch 33/100\n",
      "564/564 [==============================] - 0s 856us/step - loss: 1.8888 - accuracy: 0.3300\n",
      "Epoch 34/100\n",
      "564/564 [==============================] - 0s 842us/step - loss: 1.8637 - accuracy: 0.3437\n",
      "Epoch 35/100\n",
      "564/564 [==============================] - 0s 756us/step - loss: 1.8594 - accuracy: 0.3407\n",
      "Epoch 36/100\n",
      "564/564 [==============================] - 0s 764us/step - loss: 1.8588 - accuracy: 0.3430\n",
      "Epoch 37/100\n",
      "564/564 [==============================] - 0s 750us/step - loss: 1.8469 - accuracy: 0.3519\n",
      "Epoch 38/100\n",
      "564/564 [==============================] - 1s 905us/step - loss: 1.8295 - accuracy: 0.3561\n",
      "Epoch 39/100\n",
      "564/564 [==============================] - 0s 756us/step - loss: 1.8301 - accuracy: 0.3515\n",
      "Epoch 40/100\n",
      "564/564 [==============================] - 0s 874us/step - loss: 1.8163 - accuracy: 0.3592\n",
      "Epoch 41/100\n",
      "564/564 [==============================] - 0s 721us/step - loss: 1.8016 - accuracy: 0.3628\n",
      "Epoch 42/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 1.7951 - accuracy: 0.3662\n",
      "Epoch 43/100\n",
      "564/564 [==============================] - 0s 763us/step - loss: 1.7954 - accuracy: 0.3690\n",
      "Epoch 44/100\n",
      "564/564 [==============================] - 0s 849us/step - loss: 1.7777 - accuracy: 0.3783\n",
      "Epoch 45/100\n",
      "564/564 [==============================] - 1s 982us/step - loss: 1.7620 - accuracy: 0.3841\n",
      "Epoch 46/100\n",
      "564/564 [==============================] - 0s 825us/step - loss: 1.7717 - accuracy: 0.3742\n",
      "Epoch 47/100\n",
      "564/564 [==============================] - 0s 874us/step - loss: 1.7594 - accuracy: 0.3719\n",
      "Epoch 48/100\n",
      "564/564 [==============================] - 0s 878us/step - loss: 1.7473 - accuracy: 0.3842\n",
      "Epoch 49/100\n",
      "564/564 [==============================] - 0s 717us/step - loss: 1.7284 - accuracy: 0.3876\n",
      "Epoch 50/100\n",
      "564/564 [==============================] - 0s 754us/step - loss: 1.7266 - accuracy: 0.3944\n",
      "Epoch 51/100\n",
      "564/564 [==============================] - 0s 830us/step - loss: 1.7109 - accuracy: 0.3974\n",
      "Epoch 52/100\n",
      "564/564 [==============================] - 0s 719us/step - loss: 1.7075 - accuracy: 0.4021\n",
      "Epoch 53/100\n",
      "564/564 [==============================] - 0s 716us/step - loss: 1.6897 - accuracy: 0.4086\n",
      "Epoch 54/100\n",
      "564/564 [==============================] - 1s 954us/step - loss: 1.6823 - accuracy: 0.4089\n",
      "Epoch 55/100\n",
      "564/564 [==============================] - 0s 714us/step - loss: 1.6811 - accuracy: 0.4054\n",
      "Epoch 56/100\n",
      "564/564 [==============================] - 0s 770us/step - loss: 1.6585 - accuracy: 0.4169\n",
      "Epoch 57/100\n",
      "564/564 [==============================] - 0s 737us/step - loss: 1.6651 - accuracy: 0.4157\n",
      "Epoch 58/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.6449 - accuracy: 0.4217\n",
      "Epoch 59/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.6323 - accuracy: 0.4265\n",
      "Epoch 60/100\n",
      "564/564 [==============================] - 1s 918us/step - loss: 1.6310 - accuracy: 0.4290\n",
      "Epoch 61/100\n",
      "564/564 [==============================] - 0s 736us/step - loss: 1.6216 - accuracy: 0.4321\n",
      "Epoch 62/100\n",
      "564/564 [==============================] - 1s 906us/step - loss: 1.6097 - accuracy: 0.4410\n",
      "Epoch 63/100\n",
      "564/564 [==============================] - 0s 719us/step - loss: 1.5911 - accuracy: 0.4433\n",
      "Epoch 64/100\n",
      "564/564 [==============================] - 0s 832us/step - loss: 1.5896 - accuracy: 0.4495\n",
      "Epoch 65/100\n",
      "564/564 [==============================] - 0s 763us/step - loss: 1.5763 - accuracy: 0.4425\n",
      "Epoch 66/100\n",
      "564/564 [==============================] - 0s 779us/step - loss: 1.5730 - accuracy: 0.4466\n",
      "Epoch 67/100\n",
      "564/564 [==============================] - 0s 781us/step - loss: 1.5575 - accuracy: 0.4537\n",
      "Epoch 68/100\n",
      "564/564 [==============================] - 0s 730us/step - loss: 1.5583 - accuracy: 0.4576\n",
      "Epoch 69/100\n",
      "564/564 [==============================] - 0s 744us/step - loss: 1.5498 - accuracy: 0.4562\n",
      "Epoch 70/100\n",
      "564/564 [==============================] - 0s 776us/step - loss: 1.5423 - accuracy: 0.4608\n",
      "Epoch 71/100\n",
      "564/564 [==============================] - 0s 719us/step - loss: 1.5418 - accuracy: 0.4617\n",
      "Epoch 72/100\n",
      "564/564 [==============================] - 0s 762us/step - loss: 1.5337 - accuracy: 0.4627\n",
      "Epoch 73/100\n",
      "564/564 [==============================] - 0s 713us/step - loss: 1.5163 - accuracy: 0.4699\n",
      "Epoch 74/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.5091 - accuracy: 0.4727\n",
      "Epoch 75/100\n",
      "564/564 [==============================] - 0s 736us/step - loss: 1.4951 - accuracy: 0.4816\n",
      "Epoch 76/100\n",
      "564/564 [==============================] - 0s 776us/step - loss: 1.5055 - accuracy: 0.4660\n",
      "Epoch 77/100\n",
      "564/564 [==============================] - 0s 729us/step - loss: 1.4846 - accuracy: 0.4799\n",
      "Epoch 78/100\n",
      "564/564 [==============================] - 0s 770us/step - loss: 1.4811 - accuracy: 0.4796\n",
      "Epoch 79/100\n",
      "564/564 [==============================] - 0s 765us/step - loss: 1.4771 - accuracy: 0.4773\n",
      "Epoch 80/100\n",
      "564/564 [==============================] - 0s 770us/step - loss: 1.4705 - accuracy: 0.4835\n",
      "Epoch 81/100\n",
      "564/564 [==============================] - 0s 796us/step - loss: 1.4661 - accuracy: 0.4897\n",
      "Epoch 82/100\n",
      "564/564 [==============================] - 0s 765us/step - loss: 1.4532 - accuracy: 0.4887\n",
      "Epoch 83/100\n",
      "564/564 [==============================] - 0s 830us/step - loss: 1.4516 - accuracy: 0.4937\n",
      "Epoch 84/100\n",
      "564/564 [==============================] - 0s 773us/step - loss: 1.4367 - accuracy: 0.4992\n",
      "Epoch 85/100\n",
      "564/564 [==============================] - 0s 766us/step - loss: 1.4320 - accuracy: 0.5011\n",
      "Epoch 86/100\n",
      "564/564 [==============================] - 0s 774us/step - loss: 1.4176 - accuracy: 0.5045\n",
      "Epoch 87/100\n",
      "564/564 [==============================] - 0s 792us/step - loss: 1.4296 - accuracy: 0.5011\n",
      "Epoch 88/100\n",
      "564/564 [==============================] - 0s 733us/step - loss: 1.4202 - accuracy: 0.5033\n",
      "Epoch 89/100\n",
      "564/564 [==============================] - 0s 777us/step - loss: 1.3961 - accuracy: 0.5090\n",
      "Epoch 90/100\n",
      "564/564 [==============================] - 0s 730us/step - loss: 1.4042 - accuracy: 0.5102\n",
      "Epoch 91/100\n",
      "564/564 [==============================] - 0s 818us/step - loss: 1.3947 - accuracy: 0.5118\n",
      "Epoch 92/100\n",
      "564/564 [==============================] - 0s 781us/step - loss: 1.3915 - accuracy: 0.5159\n",
      "Epoch 93/100\n",
      "564/564 [==============================] - 0s 831us/step - loss: 1.3814 - accuracy: 0.5182\n",
      "Epoch 94/100\n",
      "564/564 [==============================] - 0s 743us/step - loss: 1.3836 - accuracy: 0.5142\n",
      "Epoch 95/100\n",
      "564/564 [==============================] - 0s 734us/step - loss: 1.3536 - accuracy: 0.5249\n",
      "Epoch 96/100\n",
      "564/564 [==============================] - 0s 740us/step - loss: 1.3800 - accuracy: 0.5152\n",
      "Epoch 97/100\n",
      "564/564 [==============================] - 0s 773us/step - loss: 1.3456 - accuracy: 0.5313\n",
      "Epoch 98/100\n",
      "564/564 [==============================] - 0s 733us/step - loss: 1.3550 - accuracy: 0.5236\n",
      "Epoch 99/100\n",
      "564/564 [==============================] - 0s 766us/step - loss: 1.3436 - accuracy: 0.5342\n",
      "Epoch 100/100\n",
      "564/564 [==============================] - 0s 746us/step - loss: 1.3462 - accuracy: 0.5283\n"
     ]
    }
   ],
   "source": [
    "print(xtr.shape)\n",
    "classifier = model.fit(xtr,ytr,epochs=100, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 55.57%\n",
      "Testing Accuracy: 17.16%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(xtr, ytr, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(xte, yte, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 10, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "564/564 [==============================] - 1s 846us/step - loss: 2.4280 - accuracy: 0.1410\n",
      "Epoch 2/100\n",
      "564/564 [==============================] - 0s 842us/step - loss: 2.3966 - accuracy: 0.1472\n",
      "Epoch 3/100\n",
      "564/564 [==============================] - 0s 874us/step - loss: 2.3917 - accuracy: 0.1525\n",
      "Epoch 4/100\n",
      "564/564 [==============================] - 1s 907us/step - loss: 2.3867 - accuracy: 0.1506\n",
      "Epoch 5/100\n",
      "564/564 [==============================] - 1s 923us/step - loss: 2.3794 - accuracy: 0.1576\n",
      "Epoch 6/100\n",
      "564/564 [==============================] - 1s 916us/step - loss: 2.3765 - accuracy: 0.1516\n",
      "Epoch 7/100\n",
      "564/564 [==============================] - 1s 955us/step - loss: 2.3708 - accuracy: 0.1553\n",
      "Epoch 8/100\n",
      "564/564 [==============================] - 1s 962us/step - loss: 2.3613 - accuracy: 0.1601\n",
      "Epoch 9/100\n",
      "564/564 [==============================] - 0s 798us/step - loss: 2.3575 - accuracy: 0.1630\n",
      "Epoch 10/100\n",
      "564/564 [==============================] - 0s 840us/step - loss: 2.3462 - accuracy: 0.1598\n",
      "Epoch 11/100\n",
      "564/564 [==============================] - 0s 875us/step - loss: 2.3380 - accuracy: 0.1688\n",
      "Epoch 12/100\n",
      "564/564 [==============================] - 1s 969us/step - loss: 2.3309 - accuracy: 0.1696\n",
      "Epoch 13/100\n",
      "564/564 [==============================] - 1s 940us/step - loss: 2.3282 - accuracy: 0.1687\n",
      "Epoch 14/100\n",
      "564/564 [==============================] - 0s 808us/step - loss: 2.3198 - accuracy: 0.1723\n",
      "Epoch 15/100\n",
      "564/564 [==============================] - 0s 873us/step - loss: 2.3148 - accuracy: 0.1720\n",
      "Epoch 16/100\n",
      "564/564 [==============================] - 0s 876us/step - loss: 2.3130 - accuracy: 0.1814\n",
      "Epoch 17/100\n",
      "564/564 [==============================] - 0s 881us/step - loss: 2.3028 - accuracy: 0.1821\n",
      "Epoch 18/100\n",
      "564/564 [==============================] - 1s 890us/step - loss: 2.3009 - accuracy: 0.1801\n",
      "Epoch 19/100\n",
      "564/564 [==============================] - 1s 904us/step - loss: 2.2951 - accuracy: 0.1785\n",
      "Epoch 20/100\n",
      "564/564 [==============================] - 0s 808us/step - loss: 2.2889 - accuracy: 0.1837\n",
      "Epoch 21/100\n",
      "564/564 [==============================] - 0s 803us/step - loss: 2.2843 - accuracy: 0.1890\n",
      "Epoch 22/100\n",
      "564/564 [==============================] - 0s 817us/step - loss: 2.2876 - accuracy: 0.1846\n",
      "Epoch 23/100\n",
      "564/564 [==============================] - 0s 811us/step - loss: 2.2753 - accuracy: 0.1889\n",
      "Epoch 24/100\n",
      "564/564 [==============================] - 1s 952us/step - loss: 2.2687 - accuracy: 0.1941\n",
      "Epoch 25/100\n",
      "564/564 [==============================] - 0s 813us/step - loss: 2.2648 - accuracy: 0.1922\n",
      "Epoch 26/100\n",
      "564/564 [==============================] - 0s 815us/step - loss: 2.2639 - accuracy: 0.1942\n",
      "Epoch 27/100\n",
      "564/564 [==============================] - 0s 849us/step - loss: 2.2534 - accuracy: 0.2005\n",
      "Epoch 28/100\n",
      "564/564 [==============================] - 0s 868us/step - loss: 2.2549 - accuracy: 0.1991\n",
      "Epoch 29/100\n",
      "564/564 [==============================] - 0s 839us/step - loss: 2.2601 - accuracy: 0.1954\n",
      "Epoch 30/100\n",
      "564/564 [==============================] - 0s 877us/step - loss: 2.2578 - accuracy: 0.2008\n",
      "Epoch 31/100\n",
      "564/564 [==============================] - 0s 760us/step - loss: 2.2471 - accuracy: 0.2048\n",
      "Epoch 32/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.2468 - accuracy: 0.1970\n",
      "Epoch 33/100\n",
      "564/564 [==============================] - 1s 955us/step - loss: 2.2437 - accuracy: 0.2009\n",
      "Epoch 34/100\n",
      "564/564 [==============================] - 1s 924us/step - loss: 2.2304 - accuracy: 0.2075\n",
      "Epoch 35/100\n",
      "564/564 [==============================] - 1s 945us/step - loss: 2.2297 - accuracy: 0.2079\n",
      "Epoch 36/100\n",
      "564/564 [==============================] - 1s 917us/step - loss: 2.2278 - accuracy: 0.2082\n",
      "Epoch 37/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.2296 - accuracy: 0.2096\n",
      "Epoch 38/100\n",
      "564/564 [==============================] - 0s 862us/step - loss: 2.2237 - accuracy: 0.2077\n",
      "Epoch 39/100\n",
      "564/564 [==============================] - 0s 836us/step - loss: 2.2130 - accuracy: 0.2062\n",
      "Epoch 40/100\n",
      "564/564 [==============================] - 1s 923us/step - loss: 2.2139 - accuracy: 0.2138\n",
      "Epoch 41/100\n",
      "564/564 [==============================] - 1s 899us/step - loss: 2.2143 - accuracy: 0.2137\n",
      "Epoch 42/100\n",
      "564/564 [==============================] - 0s 886us/step - loss: 2.1987 - accuracy: 0.2170\n",
      "Epoch 43/100\n",
      "564/564 [==============================] - 0s 805us/step - loss: 2.1974 - accuracy: 0.2178\n",
      "Epoch 44/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.1972 - accuracy: 0.2117\n",
      "Epoch 45/100\n",
      "564/564 [==============================] - 1s 952us/step - loss: 2.1990 - accuracy: 0.2153\n",
      "Epoch 46/100\n",
      "564/564 [==============================] - 1s 901us/step - loss: 2.1934 - accuracy: 0.2187\n",
      "Epoch 47/100\n",
      "564/564 [==============================] - 1s 941us/step - loss: 2.1831 - accuracy: 0.2229\n",
      "Epoch 48/100\n",
      "564/564 [==============================] - 1s 912us/step - loss: 2.1839 - accuracy: 0.2262\n",
      "Epoch 49/100\n",
      "564/564 [==============================] - 0s 804us/step - loss: 2.1837 - accuracy: 0.2233\n",
      "Epoch 50/100\n",
      "564/564 [==============================] - 0s 793us/step - loss: 2.1732 - accuracy: 0.2331\n",
      "Epoch 51/100\n",
      "564/564 [==============================] - 0s 873us/step - loss: 2.1800 - accuracy: 0.2283\n",
      "Epoch 52/100\n",
      "564/564 [==============================] - 0s 798us/step - loss: 2.1665 - accuracy: 0.2286\n",
      "Epoch 53/100\n",
      "564/564 [==============================] - 0s 816us/step - loss: 2.1636 - accuracy: 0.2300\n",
      "Epoch 54/100\n",
      "564/564 [==============================] - 0s 875us/step - loss: 2.1633 - accuracy: 0.2307\n",
      "Epoch 55/100\n",
      "564/564 [==============================] - 0s 851us/step - loss: 2.1593 - accuracy: 0.2316\n",
      "Epoch 56/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.1620 - accuracy: 0.2322\n",
      "Epoch 57/100\n",
      "564/564 [==============================] - 0s 804us/step - loss: 2.1587 - accuracy: 0.2292\n",
      "Epoch 58/100\n",
      "564/564 [==============================] - 0s 794us/step - loss: 2.1569 - accuracy: 0.2354\n",
      "Epoch 59/100\n",
      "564/564 [==============================] - 0s 791us/step - loss: 2.1431 - accuracy: 0.2373\n",
      "Epoch 60/100\n",
      "564/564 [==============================] - 0s 798us/step - loss: 2.1449 - accuracy: 0.2361\n",
      "Epoch 61/100\n",
      "564/564 [==============================] - 1s 894us/step - loss: 2.1538 - accuracy: 0.2318\n",
      "Epoch 62/100\n",
      "564/564 [==============================] - 0s 814us/step - loss: 2.1426 - accuracy: 0.2331\n",
      "Epoch 63/100\n",
      "564/564 [==============================] - 1s 992us/step - loss: 2.1495 - accuracy: 0.2372\n",
      "Epoch 64/100\n",
      "564/564 [==============================] - 0s 884us/step - loss: 2.1425 - accuracy: 0.2371\n",
      "Epoch 65/100\n",
      "564/564 [==============================] - 0s 796us/step - loss: 2.1362 - accuracy: 0.2383\n",
      "Epoch 66/100\n",
      "564/564 [==============================] - 0s 783us/step - loss: 2.1365 - accuracy: 0.2410\n",
      "Epoch 67/100\n",
      "564/564 [==============================] - 0s 847us/step - loss: 2.1240 - accuracy: 0.2452\n",
      "Epoch 68/100\n",
      "564/564 [==============================] - 1s 892us/step - loss: 2.1297 - accuracy: 0.2421\n",
      "Epoch 69/100\n",
      "564/564 [==============================] - 0s 817us/step - loss: 2.1218 - accuracy: 0.2426\n",
      "Epoch 70/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.1211 - accuracy: 0.2501\n",
      "Epoch 71/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.1206 - accuracy: 0.2478\n",
      "Epoch 72/100\n",
      "564/564 [==============================] - 1s 911us/step - loss: 2.1176 - accuracy: 0.2443\n",
      "Epoch 73/100\n",
      "564/564 [==============================] - 0s 766us/step - loss: 2.1175 - accuracy: 0.2489\n",
      "Epoch 74/100\n",
      "564/564 [==============================] - 0s 784us/step - loss: 2.1218 - accuracy: 0.2427\n",
      "Epoch 75/100\n",
      "564/564 [==============================] - 0s 820us/step - loss: 2.1096 - accuracy: 0.2520\n",
      "Epoch 76/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.1084 - accuracy: 0.2518\n",
      "Epoch 77/100\n",
      "564/564 [==============================] - 1s 946us/step - loss: 2.1194 - accuracy: 0.2490\n",
      "Epoch 78/100\n",
      "564/564 [==============================] - 1s 987us/step - loss: 2.1113 - accuracy: 0.2460\n",
      "Epoch 79/100\n",
      "564/564 [==============================] - 1s 983us/step - loss: 2.1153 - accuracy: 0.2512\n",
      "Epoch 80/100\n",
      "564/564 [==============================] - 1s 955us/step - loss: 2.1016 - accuracy: 0.2499\n",
      "Epoch 81/100\n",
      "564/564 [==============================] - 0s 833us/step - loss: 2.0963 - accuracy: 0.2481\n",
      "Epoch 82/100\n",
      "564/564 [==============================] - 0s 822us/step - loss: 2.0991 - accuracy: 0.2579\n",
      "Epoch 83/100\n",
      "564/564 [==============================] - 1s 940us/step - loss: 2.0898 - accuracy: 0.2549\n",
      "Epoch 84/100\n",
      "564/564 [==============================] - 1s 965us/step - loss: 2.0936 - accuracy: 0.2590\n",
      "Epoch 85/100\n",
      "564/564 [==============================] - 1s 1ms/step - loss: 2.0979 - accuracy: 0.2537\n",
      "Epoch 86/100\n",
      "564/564 [==============================] - 0s 814us/step - loss: 2.0754 - accuracy: 0.2635\n",
      "Epoch 87/100\n",
      "564/564 [==============================] - 0s 779us/step - loss: 2.0733 - accuracy: 0.2674\n",
      "Epoch 88/100\n",
      "564/564 [==============================] - 0s 805us/step - loss: 2.0761 - accuracy: 0.2672\n",
      "Epoch 89/100\n",
      "564/564 [==============================] - 0s 832us/step - loss: 2.0855 - accuracy: 0.2570\n",
      "Epoch 90/100\n",
      "564/564 [==============================] - 0s 836us/step - loss: 2.0850 - accuracy: 0.2629\n",
      "Epoch 91/100\n",
      "564/564 [==============================] - 0s 837us/step - loss: 2.0739 - accuracy: 0.2589\n",
      "Epoch 92/100\n",
      "564/564 [==============================] - 0s 813us/step - loss: 2.0797 - accuracy: 0.2627\n",
      "Epoch 93/100\n",
      "564/564 [==============================] - 0s 803us/step - loss: 2.0740 - accuracy: 0.2604\n",
      "Epoch 94/100\n",
      "564/564 [==============================] - 0s 869us/step - loss: 2.0703 - accuracy: 0.2690\n",
      "Epoch 95/100\n",
      "564/564 [==============================] - 0s 752us/step - loss: 2.0704 - accuracy: 0.2660\n",
      "Epoch 96/100\n",
      "564/564 [==============================] - 0s 763us/step - loss: 2.0790 - accuracy: 0.2619\n",
      "Epoch 97/100\n",
      "564/564 [==============================] - 0s 772us/step - loss: 2.0650 - accuracy: 0.2653\n",
      "Epoch 98/100\n",
      "564/564 [==============================] - 0s 777us/step - loss: 2.0610 - accuracy: 0.2731\n",
      "Epoch 99/100\n",
      "564/564 [==============================] - 0s 784us/step - loss: 2.0581 - accuracy: 0.2701\n",
      "Epoch 100/100\n",
      "564/564 [==============================] - 0s 770us/step - loss: 2.0685 - accuracy: 0.2654\n",
      "Epoch 1/100\n",
      "564/564 [==============================] - 1s 797us/step - loss: 2.4319 - accuracy: 0.1348\n",
      "Epoch 2/100\n",
      "564/564 [==============================] - 0s 775us/step - loss: 2.4055 - accuracy: 0.1481\n",
      "Epoch 3/100\n",
      "564/564 [==============================] - 0s 795us/step - loss: 2.3995 - accuracy: 0.1512\n",
      "Epoch 4/100\n",
      "564/564 [==============================] - 0s 801us/step - loss: 2.3942 - accuracy: 0.1477\n",
      "Epoch 5/100\n",
      "564/564 [==============================] - 0s 849us/step - loss: 2.3928 - accuracy: 0.1498\n",
      "Epoch 6/100\n",
      "564/564 [==============================] - 0s 849us/step - loss: 2.3922 - accuracy: 0.1435\n",
      "Epoch 7/100\n",
      "564/564 [==============================] - 1s 914us/step - loss: 2.3889 - accuracy: 0.1506\n",
      "Epoch 8/100\n",
      "564/564 [==============================] - 0s 789us/step - loss: 2.3834 - accuracy: 0.1527\n",
      "Epoch 9/100\n",
      "564/564 [==============================] - 0s 781us/step - loss: 2.3802 - accuracy: 0.1518\n",
      "Epoch 10/100\n",
      "564/564 [==============================] - 0s 787us/step - loss: 2.3793 - accuracy: 0.1504\n",
      "Epoch 11/100\n",
      "564/564 [==============================] - 0s 826us/step - loss: 2.3691 - accuracy: 0.1559\n",
      "Epoch 12/100\n",
      "564/564 [==============================] - 0s 856us/step - loss: 2.3687 - accuracy: 0.1546\n",
      "Epoch 13/100\n",
      "564/564 [==============================] - 0s 861us/step - loss: 2.3609 - accuracy: 0.1566\n",
      "Epoch 14/100\n",
      "  1/564 [..............................] - ETA: 0s - loss: 2.3589 - accuracy: 0.1500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f8791025c45e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lalitesh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train, test in folds.split(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(256, activation='sigmoid', input_shape=(xtr.shape[1],)))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    classifier = model.fit(xtr,ytr,epochs=100, batch_size=40)\n",
    "    score = model.evaluate(xtr, ytr, verbose=0)\n",
    "    scores.append(score[1]*100)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this model did not train very well and the highest accuracy achieved was 50% on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
